{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,LSTM\n",
    "from keras import optimizers\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = genfromtxt('dataset1.csv',delimiter=',')\n",
    "dataset2 = genfromtxt('dataset2.csv',delimiter=',')\n",
    "dataset3 = genfromtxt('dataset3.csv',delimiter=',')\n",
    "dataset4 = genfromtxt('dataset4.csv',delimiter=',')\n",
    "dataset5 = genfromtxt('dataset5.csv',delimiter=',')\n",
    "dataset6 = genfromtxt('dataset6.csv',delimiter=',')\n",
    "dataset7 = genfromtxt('dataset7.csv',delimiter=',')\n",
    "dataset8 = genfromtxt('dataset8.csv',delimiter=',')\n",
    "dataset9 = genfromtxt('dataset9.csv',delimiter=',')\n",
    "dataset10 = genfromtxt('dataset10.csv',delimiter=',')\n",
    "dataset11 = genfromtxt('dataset11.csv',delimiter=',')\n",
    "dataset12 = genfromtxt('dataset12.csv',delimiter=',')\n",
    "dataset13 = genfromtxt('dataset13.csv',delimiter=',')\n",
    "dataset14 = genfromtxt('dataset14.csv',delimiter=',')\n",
    "dataset15 = genfromtxt('dataset15.csv',delimiter=',')\n",
    "dataset16 = genfromtxt('dataset16.csv',delimiter=',')\n",
    "dataset17 = genfromtxt('dataset17.csv',delimiter=',')\n",
    "dataset18 = genfromtxt('dataset18.csv',delimiter=',')\n",
    "dataset19 = genfromtxt('dataset19.csv',delimiter=',')\n",
    "dataset20 = genfromtxt('dataset20.csv',delimiter=',')\n",
    "dataset21 = genfromtxt('dataset21.csv',delimiter=',')\n",
    "dataset22 = genfromtxt('dataset22.csv',delimiter=',')\n",
    "dataset23 = genfromtxt('dataset23.csv',delimiter=',')\n",
    "dataset24 = genfromtxt('dataset24.csv',delimiter=',')\n",
    "dataset25 = genfromtxt('dataset25.csv',delimiter=',')\n",
    "dataset26 = genfromtxt('dataset26.csv',delimiter=',')\n",
    "dataset27 = genfromtxt('dataset27.csv',delimiter=',')\n",
    "dataset28 = genfromtxt('dataset28.csv',delimiter=',')\n",
    "dataset29 = genfromtxt('dataset29.csv',delimiter=',')\n",
    "dataset30 = genfromtxt('dataset30.csv',delimiter=',')\n",
    "dataset31 = genfromtxt('dataset31.csv',delimiter=',')\n",
    "dataset32 = genfromtxt('dataset32.csv',delimiter=',')\n",
    "dataset33 = genfromtxt('dataset33.csv',delimiter=',')\n",
    "dataset34 = genfromtxt('dataset34.csv',delimiter=',')\n",
    "dataset35 = genfromtxt('dataset35.csv',delimiter=',')\n",
    "dataset36 = genfromtxt('dataset36.csv',delimiter=',')\n",
    "dataset37 = genfromtxt('dataset37.csv',delimiter=',')\n",
    "dataset38 = genfromtxt('dataset38.csv',delimiter=',')\n",
    "dataset39 = genfromtxt('dataset39.csv',delimiter=',')\n",
    "dataset40 = genfromtxt('dataset40.csv',delimiter=',')\n",
    "dataset41 = genfromtxt('dataset41.csv',delimiter=',')\n",
    "dataset42 = genfromtxt('dataset42.csv',delimiter=',')\n",
    "dataset43 = genfromtxt('dataset43.csv',delimiter=',')\n",
    "dataset44 = genfromtxt('dataset44.csv',delimiter=',')\n",
    "dataset45 = genfromtxt('dataset45.csv',delimiter=',')\n",
    "dataset46 = genfromtxt('dataset46.csv',delimiter=',')\n",
    "dataset47 = genfromtxt('dataset47.csv',delimiter=',')\n",
    "dataset48 = genfromtxt('dataset48.csv',delimiter=',')\n",
    "outputtrain = genfromtxt('output24hr.csv',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanorm = np.concatenate((dataset1,dataset2,dataset3,dataset4,dataset5,dataset6,dataset7,dataset8,dataset9,dataset10,\n",
    "                                          dataset11,dataset12,dataset13,dataset14,dataset15,dataset16,dataset17,dataset18,dataset19,dataset20,\n",
    "                                          dataset21,dataset22,dataset23,dataset24,dataset25,dataset26,dataset27,dataset28,dataset29,dataset30,\n",
    "                                          dataset31,dataset32,dataset33,dataset34,dataset35,dataset36,dataset37,dataset38,dataset39,dataset40,\n",
    "                                          dataset41,dataset42,dataset43,dataset44,dataset45,dataset46,dataset47,dataset48))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(datanorm)\n",
    "dataset1 = scaler.transform(dataset1)\n",
    "dataset2 = scaler.transform(dataset2)\n",
    "dataset3 = scaler.transform(dataset3)\n",
    "dataset4 = scaler.transform(dataset4)\n",
    "dataset5 = scaler.transform(dataset5)\n",
    "dataset6 = scaler.transform(dataset6)\n",
    "dataset7 = scaler.transform(dataset7)\n",
    "dataset8 = scaler.transform(dataset8)\n",
    "dataset9 = scaler.transform(dataset9)\n",
    "dataset10 = scaler.transform(dataset10)\n",
    "dataset11 = scaler.transform(dataset11)\n",
    "dataset12 = scaler.transform(dataset12)\n",
    "dataset13 = scaler.transform(dataset13)\n",
    "dataset14 = scaler.transform(dataset14)\n",
    "dataset15 = scaler.transform(dataset15)\n",
    "dataset16 = scaler.transform(dataset16)\n",
    "dataset17 = scaler.transform(dataset17)\n",
    "dataset18 = scaler.transform(dataset18)\n",
    "dataset19 = scaler.transform(dataset19)\n",
    "dataset20 = scaler.transform(dataset20)\n",
    "dataset21 = scaler.transform(dataset21)\n",
    "dataset22 = scaler.transform(dataset22)\n",
    "dataset23 = scaler.transform(dataset23)\n",
    "dataset24 = scaler.transform(dataset24)\n",
    "dataset25 = scaler.transform(dataset25)\n",
    "dataset26 = scaler.transform(dataset26)\n",
    "dataset27 = scaler.transform(dataset27)\n",
    "dataset28 = scaler.transform(dataset28)\n",
    "dataset29 = scaler.transform(dataset29)\n",
    "dataset30 = scaler.transform(dataset30)\n",
    "dataset31 = scaler.transform(dataset31)\n",
    "dataset32 = scaler.transform(dataset32)\n",
    "dataset33 = scaler.transform(dataset33)\n",
    "dataset34 = scaler.transform(dataset34)\n",
    "dataset35 = scaler.transform(dataset35)\n",
    "dataset36 = scaler.transform(dataset36)\n",
    "dataset37 = scaler.transform(dataset37)\n",
    "dataset38 = scaler.transform(dataset38)\n",
    "dataset39 = scaler.transform(dataset39)\n",
    "dataset40 = scaler.transform(dataset40)\n",
    "dataset41 = scaler.transform(dataset41)\n",
    "dataset42 = scaler.transform(dataset42)\n",
    "dataset43 = scaler.transform(dataset43)\n",
    "dataset44 = scaler.transform(dataset44)\n",
    "dataset45 = scaler.transform(dataset45)\n",
    "dataset46 = scaler.transform(dataset46)\n",
    "dataset47 = scaler.transform(dataset47)\n",
    "dataset48 = scaler.transform(dataset48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax=[]\n",
    "data1 = dataset1[0:len(dataset1)-24,:]\n",
    "for x in range(len(data1)-11):\n",
    "    datax.append(data1[0+x:12+x,:])\n",
    "data2 = dataset2[0:len(dataset2)-24,:]\n",
    "for x in range(len(data2)-11):\n",
    "    datax.append(data2[0+x:12+x,:])\n",
    "data3 = dataset3[0:len(dataset3)-24,:]\n",
    "for x in range(len(data3)-11):\n",
    "    datax.append(data3[0+x:12+x,:])\n",
    "data4 = dataset4[0:len(dataset4)-24,:]\n",
    "for x in range(len(data4)-11):\n",
    "    datax.append(data4[0+x:12+x,:])\n",
    "data5 = dataset5[0:len(dataset5)-24,:]\n",
    "for x in range(len(data5)-11):\n",
    "    datax.append(data5[0+x:12+x,:])\n",
    "data6 = dataset6[0:len(dataset6)-24,:]\n",
    "for x in range(len(data6)-11):\n",
    "    datax.append(data6[0+x:12+x,:])\n",
    "data7 = dataset7[0:len(dataset7)-24,:]\n",
    "for x in range(len(data7)-11):\n",
    "    datax.append(data7[0+x:12+x,:])\n",
    "data8 = dataset8[0:len(dataset8)-24,:]\n",
    "for x in range(len(data8)-11):\n",
    "    datax.append(data8[0+x:12+x,:])\n",
    "data9 = dataset9[0:len(dataset9)-24,:]\n",
    "for x in range(len(data9)-11):\n",
    "    datax.append(data9[0+x:12+x,:])\n",
    "data10 = dataset10[0:len(dataset10)-24,:]\n",
    "for x in range(len(data10)-11):\n",
    "    datax.append(data10[0+x:12+x,:])\n",
    "data11 = dataset11[0:len(dataset11)-24,:]\n",
    "for x in range(len(data11)-11):\n",
    "    datax.append(data11[0+x:12+x,:])\n",
    "data12 = dataset12[0:len(dataset12)-24,:]\n",
    "for x in range(len(data12)-11):\n",
    "    datax.append(data12[0+x:12+x,:])\n",
    "data13 = dataset13[0:len(dataset13)-24,:]\n",
    "for x in range(len(data13)-11):\n",
    "    datax.append(data13[0+x:12+x,:])\n",
    "data14 = dataset14[0:len(dataset14)-24,:]\n",
    "for x in range(len(data14)-11):\n",
    "    datax.append(data14[0+x:12+x,:])\n",
    "data15 = dataset15[0:len(dataset15)-24,:]\n",
    "for x in range(len(data15)-11):\n",
    "    datax.append(data15[0+x:12+x,:])\n",
    "data16 = dataset16[0:len(dataset16)-24,:]\n",
    "for x in range(len(data16)-11):\n",
    "    datax.append(data16[0+x:12+x,:])\n",
    "data17 = dataset17[0:len(dataset17)-24,:]\n",
    "for x in range(len(data17)-11):\n",
    "    datax.append(data17[0+x:12+x,:])\n",
    "data18 = dataset18[0:len(dataset18)-24,:]\n",
    "for x in range(len(data18)-11):\n",
    "    datax.append(data18[0+x:12+x,:])\n",
    "data19 = dataset19[0:len(dataset19)-24,:]\n",
    "for x in range(len(data19)-11):\n",
    "    datax.append(data19[0+x:12+x,:])\n",
    "data20 = dataset20[0:len(dataset20)-24,:]\n",
    "for x in range(len(data20)-11):\n",
    "    datax.append(data20[0+x:12+x,:])\n",
    "data21 = dataset21[0:len(dataset21)-24,:]\n",
    "for x in range(len(data21)-11):\n",
    "    datax.append(data21[0+x:12+x,:])\n",
    "data22 = dataset22[0:len(dataset22)-24,:]\n",
    "for x in range(len(data22)-11):\n",
    "    datax.append(data22[0+x:12+x,:])\n",
    "data23 = dataset23[0:len(dataset23)-24,:]\n",
    "for x in range(len(data23)-11):\n",
    "    datax.append(data23[0+x:12+x,:])\n",
    "data24 = dataset24[0:len(dataset24)-24,:]\n",
    "for x in range(len(data24)-11):\n",
    "    datax.append(data24[0+x:12+x,:])\n",
    "data25 = dataset25[0:len(dataset25)-24,:]\n",
    "for x in range(len(data25)-11):\n",
    "    datax.append(data25[0+x:12+x,:])\n",
    "data26 = dataset26[0:len(dataset26)-24,:]\n",
    "for x in range(len(data26)-11):\n",
    "    datax.append(data26[0+x:12+x,:])\n",
    "data27 = dataset27[0:len(dataset27)-24,:]\n",
    "for x in range(len(data27)-11):\n",
    "    datax.append(data27[0+x:12+x,:])\n",
    "data28 = dataset28[0:len(dataset28)-24,:]\n",
    "for x in range(len(data28)-11):\n",
    "    datax.append(data28[0+x:12+x,:])\n",
    "data29 = dataset29[0:len(dataset29)-24,:]\n",
    "for x in range(len(data29)-11):\n",
    "    datax.append(data29[0+x:12+x,:])\n",
    "data30 = dataset30[0:len(dataset30)-24,:]\n",
    "for x in range(len(data30)-11):\n",
    "    datax.append(data30[0+x:12+x,:])\n",
    "data31 = dataset31[0:len(dataset31)-24,:]\n",
    "for x in range(len(data31)-11):\n",
    "    datax.append(data31[0+x:12+x,:])\n",
    "data32 = dataset32[0:len(dataset32)-24,:]\n",
    "for x in range(len(data32)-11):\n",
    "    datax.append(data32[0+x:12+x,:])\n",
    "data33 = dataset33[0:len(dataset33)-24,:]\n",
    "for x in range(len(data33)-11):\n",
    "    datax.append(data33[0+x:12+x,:])\n",
    "data34 = dataset34[0:len(dataset34)-24,:]\n",
    "for x in range(len(data34)-11):\n",
    "    datax.append(data34[0+x:12+x,:])\n",
    "data35 = dataset35[0:len(dataset35)-24,:]\n",
    "for x in range(len(data35)-11):\n",
    "    datax.append(data35[0+x:12+x,:])\n",
    "data36 = dataset36[0:len(dataset36)-24,:]\n",
    "for x in range(len(data36)-11):\n",
    "    datax.append(data36[0+x:12+x,:])\n",
    "data37 = dataset37[0:len(dataset37)-24,:]\n",
    "for x in range(len(data37)-11):\n",
    "    datax.append(data37[0+x:12+x,:])\n",
    "data38 = dataset38[0:len(dataset38)-24,:]\n",
    "for x in range(len(data38)-11):\n",
    "    datax.append(data38[0+x:12+x,:])\n",
    "data39 = dataset39[0:len(dataset39)-24,:]\n",
    "for x in range(len(data39)-11):\n",
    "    datax.append(data39[0+x:12+x,:])\n",
    "data40 = dataset40[0:len(dataset40)-24,:]\n",
    "for x in range(len(data40)-11):\n",
    "    datax.append(data40[0+x:12+x,:])\n",
    "data41 = dataset41[0:len(dataset41)-24,:]\n",
    "for x in range(len(data41)-11):\n",
    "    datax.append(data41[0+x:12+x,:])\n",
    "data42 = dataset42[0:len(dataset42)-24,:]\n",
    "for x in range(len(data42)-11):\n",
    "    datax.append(data42[0+x:12+x,:])\n",
    "data43 = dataset43[0:len(dataset43)-24,:]\n",
    "for x in range(len(data43)-11):\n",
    "    datax.append(data43[0+x:12+x,:])\n",
    "data44 = dataset44[0:len(dataset44)-24,:]\n",
    "for x in range(len(data44)-11):\n",
    "    datax.append(data44[0+x:12+x,:])\n",
    "data45 = dataset45[0:len(dataset45)-24,:]\n",
    "for x in range(len(data45)-11):\n",
    "    datax.append(data45[0+x:12+x,:])\n",
    "data46 = dataset46[0:len(dataset46)-24,:]\n",
    "for x in range(len(data46)-11):\n",
    "    datax.append(data46[0+x:12+x,:])\n",
    "data47 = dataset47[0:len(dataset47)-24,:]\n",
    "for x in range(len(data47)-11):\n",
    "    datax.append(data47[0+x:12+x,:])\n",
    "data48 = dataset48[0:len(dataset48)-24,:]\n",
    "for x in range(len(data48)-11):\n",
    "    datax.append(data48[0+x:12+x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32448\n",
      "32448\n"
     ]
    }
   ],
   "source": [
    "print(len(datax))\n",
    "print(len(outputtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.07320471e-01  6.72131425e-02  1.12802337e+00 -6.71729323e-01\n",
      "   -3.22606330e-01 -2.51720472e-01]\n",
      "  [ 3.06067074e-01  2.37421342e-02  1.27016940e+00 -6.92282761e-01\n",
      "   -3.88381538e-01 -2.51720472e-01]\n",
      "  [ 2.07320471e-01  2.37421342e-02  1.36493342e+00 -6.71729323e-01\n",
      "   -5.19931953e-01 -2.51720472e-01]\n",
      "  ...\n",
      "  [ 2.07320471e-01  1.32419655e-01  1.27016940e+00 -7.33389637e-01\n",
      "   -1.91055915e-01 -3.04798964e-02]\n",
      "  [-1.38292641e-01  2.00663009e-03  1.64922548e+00 -8.36156826e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-8.89193389e-02 -6.31998823e-02  1.93351754e+00 -8.36156826e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]]\n",
      "\n",
      " [[ 3.06067074e-01  2.37421342e-02  1.27016940e+00 -6.92282761e-01\n",
      "   -3.88381538e-01 -2.51720472e-01]\n",
      "  [ 2.07320471e-01  2.37421342e-02  1.36493342e+00 -6.71729323e-01\n",
      "   -5.19931953e-01 -2.51720472e-01]\n",
      "  [ 2.56693772e-01  1.32419655e-01  1.17540538e+00 -6.71729323e-01\n",
      "   -4.54156746e-01 -2.51720472e-01]\n",
      "  ...\n",
      "  [-1.38292641e-01  2.00663009e-03  1.64922548e+00 -8.36156826e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-8.89193389e-02 -6.31998823e-02  1.93351754e+00 -8.36156826e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-4.34532450e-01 -1.97288740e-02  2.02828156e+00 -8.36156826e-01\n",
      "   -5.19931953e-01 -3.04798964e-02]]\n",
      "\n",
      " [[ 2.07320471e-01  2.37421342e-02  1.36493342e+00 -6.71729323e-01\n",
      "   -5.19931953e-01 -2.51720472e-01]\n",
      "  [ 2.56693772e-01  1.32419655e-01  1.17540538e+00 -6.71729323e-01\n",
      "   -4.54156746e-01 -2.51720472e-01]\n",
      "  [ 5.92005659e-02 -4.14643782e-02  7.48967295e-01 -6.10069010e-01\n",
      "   -5.95054995e-02 -2.51720472e-01]\n",
      "  ...\n",
      "  [-8.89193389e-02 -6.31998823e-02  1.93351754e+00 -8.36156826e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-4.34532450e-01 -1.97288740e-02  2.02828156e+00 -8.36156826e-01\n",
      "   -5.19931953e-01 -3.04798964e-02]\n",
      "  [-2.37039244e-01 -3.02290428e-01  2.17042759e+00 -8.77263702e-01\n",
      "   -5.85707161e-01 -3.04798964e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.38292641e-01 -4.76174461e-01  1.80383176e-01 -1.43220652e+00\n",
      "   -1.04613361e+00 -4.72961048e-01]\n",
      "  [-3.35785847e-01 -5.41380973e-01 -1.00416707e+00 -6.10069010e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-6.32025657e-01 -6.50058494e-01  9.38495334e-01 -1.43220652e+00\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  ...\n",
      "  [-1.38292641e-01 -1.50141899e-01  2.75147196e-01 -4.04534632e-01\n",
      "    2.03595331e-01  1.90760680e-01]\n",
      "  [-2.86412545e-01 -4.76174461e-01 -5.65268728e-02 -4.04534632e-01\n",
      "    2.69370539e-01 -3.04798964e-02]\n",
      "  [ 9.82726432e-03 -3.02290428e-01 -6.72493001e-01 -1.99000253e-01\n",
      "    8.61347408e-01  1.90760680e-01]]\n",
      "\n",
      " [[-3.35785847e-01 -5.41380973e-01 -1.00416707e+00 -6.10069010e-01\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-6.32025657e-01 -6.50058494e-01  9.38495334e-01 -1.43220652e+00\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-3.85159149e-01 -6.06587486e-01  1.17540538e+00 -1.43220652e+00\n",
      "   -1.04613361e+00 -4.72961048e-01]\n",
      "  ...\n",
      "  [-2.86412545e-01 -4.76174461e-01 -5.65268728e-02 -4.04534632e-01\n",
      "    2.69370539e-01 -3.04798964e-02]\n",
      "  [ 9.82726432e-03 -3.02290428e-01 -6.72493001e-01 -1.99000253e-01\n",
      "    8.61347408e-01  1.90760680e-01]\n",
      "  [ 1.57947169e-01 -1.06670891e-01 -9.09403050e-01  6.53412502e-03\n",
      "    1.12444824e+00  1.90760680e-01]]\n",
      "\n",
      " [[-6.32025657e-01 -6.50058494e-01  9.38495334e-01 -1.43220652e+00\n",
      "   -4.54156746e-01 -3.04798964e-02]\n",
      "  [-3.85159149e-01 -6.06587486e-01  1.17540538e+00 -1.43220652e+00\n",
      "   -1.04613361e+00 -4.72961048e-01]\n",
      "  [ 1.08573868e-01 -3.24025932e-01 -1.00416707e+00 -6.10069010e-01\n",
      "   -3.88381538e-01  4.12001256e-01]\n",
      "  ...\n",
      "  [ 9.82726432e-03 -3.02290428e-01 -6.72493001e-01 -1.99000253e-01\n",
      "    8.61347408e-01  1.90760680e-01]\n",
      "  [ 1.57947169e-01 -1.06670891e-01 -9.09403050e-01  6.53412502e-03\n",
      "    1.12444824e+00  1.90760680e-01]\n",
      "  [ 1.57947169e-01 -8.49353864e-02 -9.56785060e-01  6.53412502e-03\n",
      "    9.27122616e-01 -3.04798964e-02]]]\n",
      "[3. 3. 2. ... 2. 2. 2.]\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "datax = np.array(datax,np.float64)\n",
    "x_train = np.array(datax,np.float64)\n",
    "outputtrain = np.array(outputtrain,np.float64)\n",
    "y_train = to_categorical(outputtrain)\n",
    "print(x_train)\n",
    "print(outputtrain)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 6\n",
    "timesteps = 12\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,input_shape=(timesteps,data_dim),return_sequences=True))#True = many to many\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 12, 32)            4992      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 12, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 21,830\n",
      "Trainable params: 21,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25548/25548 [==============================] - 21s 816us/step - loss: 1.0267 - acc: 0.56074s - loss: 1.0457 -\n",
      "Epoch 2/100\n",
      "25548/25548 [==============================] - 17s 674us/step - loss: 0.9158 - acc: 0.61040s - loss: 0.9156 - ac\n",
      "Epoch 3/100\n",
      "25548/25548 [==============================] - 17s 672us/step - loss: 0.8819 - acc: 0.6245\n",
      "Epoch 4/100\n",
      "25548/25548 [==============================] - 17s 683us/step - loss: 0.8560 - acc: 0.6364\n",
      "Epoch 5/100\n",
      "25548/25548 [==============================] - 18s 693us/step - loss: 0.8318 - acc: 0.6482\n",
      "Epoch 6/100\n",
      "25548/25548 [==============================] - 17s 684us/step - loss: 0.8107 - acc: 0.6577\n",
      "Epoch 7/100\n",
      "25548/25548 [==============================] - 18s 697us/step - loss: 0.7911 - acc: 0.66160s - loss: 0.7910 - acc: 0.66\n",
      "Epoch 8/100\n",
      "25548/25548 [==============================] - 18s 691us/step - loss: 0.7717 - acc: 0.6720\n",
      "Epoch 9/100\n",
      "25548/25548 [==============================] - 17s 680us/step - loss: 0.7496 - acc: 0.6839\n",
      "Epoch 10/100\n",
      "25548/25548 [==============================] - 18s 694us/step - loss: 0.7307 - acc: 0.69210s - loss: 0.7308 - acc: 0.6\n",
      "Epoch 11/100\n",
      "25548/25548 [==============================] - 18s 697us/step - loss: 0.7113 - acc: 0.7005\n",
      "Epoch 12/100\n",
      "25548/25548 [==============================] - 18s 700us/step - loss: 0.6928 - acc: 0.7102\n",
      "Epoch 13/100\n",
      "25548/25548 [==============================] - 18s 690us/step - loss: 0.6731 - acc: 0.7177\n",
      "Epoch 14/100\n",
      "25548/25548 [==============================] - 18s 696us/step - loss: 0.6561 - acc: 0.7262\n",
      "Epoch 15/100\n",
      "25548/25548 [==============================] - 18s 694us/step - loss: 0.6376 - acc: 0.7330\n",
      "Epoch 16/100\n",
      "25548/25548 [==============================] - 18s 687us/step - loss: 0.6198 - acc: 0.7404\n",
      "Epoch 17/100\n",
      "25548/25548 [==============================] - 17s 674us/step - loss: 0.6050 - acc: 0.7500\n",
      "Epoch 18/100\n",
      "25548/25548 [==============================] - 17s 666us/step - loss: 0.5869 - acc: 0.7610\n",
      "Epoch 19/100\n",
      "25548/25548 [==============================] - 17s 667us/step - loss: 0.5700 - acc: 0.7675\n",
      "Epoch 20/100\n",
      "25548/25548 [==============================] - 17s 670us/step - loss: 0.5528 - acc: 0.7729\n",
      "Epoch 21/100\n",
      "25548/25548 [==============================] - 17s 668us/step - loss: 0.5422 - acc: 0.7791\n",
      "Epoch 22/100\n",
      "25548/25548 [==============================] - 17s 665us/step - loss: 0.5245 - acc: 0.7843\n",
      "Epoch 23/100\n",
      "25548/25548 [==============================] - 17s 662us/step - loss: 0.5113 - acc: 0.7906\n",
      "Epoch 24/100\n",
      "25548/25548 [==============================] - 17s 672us/step - loss: 0.4963 - acc: 0.7985\n",
      "Epoch 25/100\n",
      "25548/25548 [==============================] - 17s 656us/step - loss: 0.4837 - acc: 0.8021\n",
      "Epoch 26/100\n",
      "25548/25548 [==============================] - 17s 654us/step - loss: 0.4743 - acc: 0.8090\n",
      "Epoch 27/100\n",
      "25548/25548 [==============================] - 17s 656us/step - loss: 0.4581 - acc: 0.8158\n",
      "Epoch 28/100\n",
      "25548/25548 [==============================] - 17s 661us/step - loss: 0.4447 - acc: 0.8217\n",
      "Epoch 29/100\n",
      "25548/25548 [==============================] - 17s 679us/step - loss: 0.4323 - acc: 0.8280\n",
      "Epoch 30/100\n",
      "25548/25548 [==============================] - 21s 806us/step - loss: 0.4227 - acc: 0.8317\n",
      "Epoch 31/100\n",
      "25548/25548 [==============================] - 21s 812us/step - loss: 0.4101 - acc: 0.8371\n",
      "Epoch 32/100\n",
      "25548/25548 [==============================] - 21s 810us/step - loss: 0.4036 - acc: 0.8388\n",
      "Epoch 33/100\n",
      "25548/25548 [==============================] - 21s 808us/step - loss: 0.3876 - acc: 0.8464\n",
      "Epoch 34/100\n",
      "25548/25548 [==============================] - 20s 800us/step - loss: 0.3825 - acc: 0.8501\n",
      "Epoch 35/100\n",
      "25548/25548 [==============================] - 21s 809us/step - loss: 0.3678 - acc: 0.8561\n",
      "Epoch 36/100\n",
      "25548/25548 [==============================] - 21s 804us/step - loss: 0.3637 - acc: 0.8569\n",
      "Epoch 37/100\n",
      "25548/25548 [==============================] - 20s 797us/step - loss: 0.3519 - acc: 0.8633\n",
      "Epoch 38/100\n",
      "25548/25548 [==============================] - 21s 806us/step - loss: 0.3448 - acc: 0.8654\n",
      "Epoch 39/100\n",
      "25548/25548 [==============================] - 20s 788us/step - loss: 0.3371 - acc: 0.8687\n",
      "Epoch 40/100\n",
      "25548/25548 [==============================] - 20s 778us/step - loss: 0.3277 - acc: 0.8728\n",
      "Epoch 41/100\n",
      "25548/25548 [==============================] - 20s 774us/step - loss: 0.3163 - acc: 0.87880s - loss: 0.3166 - acc\n",
      "Epoch 42/100\n",
      "25548/25548 [==============================] - 20s 765us/step - loss: 0.3099 - acc: 0.8792\n",
      "Epoch 43/100\n",
      "25548/25548 [==============================] - 20s 776us/step - loss: 0.3036 - acc: 0.8830\n",
      "Epoch 44/100\n",
      "25548/25548 [==============================] - 20s 764us/step - loss: 0.2946 - acc: 0.8877\n",
      "Epoch 45/100\n",
      "25548/25548 [==============================] - 20s 771us/step - loss: 0.2890 - acc: 0.8899\n",
      "Epoch 46/100\n",
      "25548/25548 [==============================] - 19s 761us/step - loss: 0.2807 - acc: 0.8927\n",
      "Epoch 47/100\n",
      "25548/25548 [==============================] - 20s 768us/step - loss: 0.2757 - acc: 0.8965\n",
      "Epoch 48/100\n",
      "25548/25548 [==============================] - 20s 766us/step - loss: 0.2734 - acc: 0.8953\n",
      "Epoch 49/100\n",
      "25548/25548 [==============================] - 19s 755us/step - loss: 0.2634 - acc: 0.90001s - l\n",
      "Epoch 50/100\n",
      "25548/25548 [==============================] - 19s 755us/step - loss: 0.2537 - acc: 0.9034\n",
      "Epoch 51/100\n",
      "25548/25548 [==============================] - 19s 762us/step - loss: 0.2563 - acc: 0.9047\n",
      "Epoch 52/100\n",
      "25548/25548 [==============================] - 19s 752us/step - loss: 0.2516 - acc: 0.9059\n",
      "Epoch 53/100\n",
      "25548/25548 [==============================] - 19s 751us/step - loss: 0.2407 - acc: 0.9102\n",
      "Epoch 54/100\n",
      "25548/25548 [==============================] - 19s 751us/step - loss: 0.2366 - acc: 0.9110\n",
      "Epoch 55/100\n",
      "25548/25548 [==============================] - 19s 759us/step - loss: 0.2287 - acc: 0.9153\n",
      "Epoch 56/100\n",
      "25548/25548 [==============================] - 19s 756us/step - loss: 0.2248 - acc: 0.9152\n",
      "Epoch 57/100\n",
      "25548/25548 [==============================] - 19s 736us/step - loss: 0.2240 - acc: 0.91890s - loss: 0.2233 - \n",
      "Epoch 58/100\n",
      "25548/25548 [==============================] - 19s 741us/step - loss: 0.2185 - acc: 0.9218\n",
      "Epoch 59/100\n",
      "25548/25548 [==============================] - 19s 745us/step - loss: 0.2126 - acc: 0.9234\n",
      "Epoch 60/100\n",
      "25548/25548 [==============================] - 19s 747us/step - loss: 0.2047 - acc: 0.9242\n",
      "Epoch 61/100\n",
      "25548/25548 [==============================] - 19s 735us/step - loss: 0.2042 - acc: 0.9260\n",
      "Epoch 62/100\n",
      "25548/25548 [==============================] - 19s 736us/step - loss: 0.1974 - acc: 0.9273\n",
      "Epoch 63/100\n",
      "25548/25548 [==============================] - 19s 732us/step - loss: 0.1960 - acc: 0.9296\n",
      "Epoch 64/100\n",
      "25548/25548 [==============================] - 19s 744us/step - loss: 0.1929 - acc: 0.9300\n",
      "Epoch 65/100\n",
      "25548/25548 [==============================] - 19s 729us/step - loss: 0.1893 - acc: 0.9317\n",
      "Epoch 66/100\n",
      "25548/25548 [==============================] - 19s 731us/step - loss: 0.1805 - acc: 0.9338\n",
      "Epoch 67/100\n",
      "25548/25548 [==============================] - 19s 734us/step - loss: 0.1813 - acc: 0.9333\n",
      "Epoch 68/100\n",
      "25548/25548 [==============================] - 21s 832us/step - loss: 0.1739 - acc: 0.9377\n",
      "Epoch 69/100\n",
      "25548/25548 [==============================] - 22s 845us/step - loss: 0.1718 - acc: 0.9385\n",
      "Epoch 70/100\n",
      "25548/25548 [==============================] - 21s 840us/step - loss: 0.1700 - acc: 0.9390\n",
      "Epoch 71/100\n",
      "25548/25548 [==============================] - 20s 778us/step - loss: 0.1701 - acc: 0.93899s - loss: 0.1669 - ac - ETA: 8s - loss: 0.1673 - acc:  - ETA:  - ETA: 0s - loss: 0.1699 - acc: 0\n",
      "Epoch 72/100\n",
      "25548/25548 [==============================] - 368s 14ms/step - loss: 0.1671 - acc: 0.9392\n",
      "Epoch 73/100\n",
      "25548/25548 [==============================] - 13s 502us/step - loss: 0.1613 - acc: 0.9426\n",
      "Epoch 74/100\n",
      "25548/25548 [==============================] - 13s 492us/step - loss: 0.1631 - acc: 0.9413\n",
      "Epoch 75/100\n",
      "25548/25548 [==============================] - 13s 496us/step - loss: 0.1614 - acc: 0.9434\n",
      "Epoch 76/100\n",
      "25548/25548 [==============================] - 12s 487us/step - loss: 0.1564 - acc: 0.9435\n",
      "Epoch 77/100\n",
      "25548/25548 [==============================] - 13s 500us/step - loss: 0.1550 - acc: 0.9450\n",
      "Epoch 78/100\n",
      "25548/25548 [==============================] - 13s 503us/step - loss: 0.1503 - acc: 0.9472\n",
      "Epoch 79/100\n",
      "25548/25548 [==============================] - 19s 752us/step - loss: 0.1493 - acc: 0.9464\n",
      "Epoch 80/100\n",
      "25548/25548 [==============================] - 22s 873us/step - loss: 0.1483 - acc: 0.9488\n",
      "Epoch 81/100\n",
      "25548/25548 [==============================] - 22s 871us/step - loss: 0.1448 - acc: 0.9488\n",
      "Epoch 82/100\n",
      "25548/25548 [==============================] - 22s 872us/step - loss: 0.1438 - acc: 0.9504\n",
      "Epoch 83/100\n",
      "25548/25548 [==============================] - 22s 872us/step - loss: 0.1379 - acc: 0.9519ETA: 2s - loss: 0.1341 - ac - ETA: 2s - loss: 0.1349 - acc:  - E\n",
      "Epoch 84/100\n",
      "25548/25548 [==============================] - 22s 868us/step - loss: 0.1382 - acc: 0.95081s - \n",
      "Epoch 85/100\n",
      "25548/25548 [==============================] - 22s 870us/step - loss: 0.1367 - acc: 0.9521\n",
      "Epoch 86/100\n",
      "25548/25548 [==============================] - 22s 859us/step - loss: 0.1340 - acc: 0.9524\n",
      "Epoch 87/100\n",
      "25548/25548 [==============================] - 22s 863us/step - loss: 0.1317 - acc: 0.9545\n",
      "Epoch 88/100\n",
      "25548/25548 [==============================] - 22s 844us/step - loss: 0.1321 - acc: 0.9547\n",
      "Epoch 89/100\n",
      "25548/25548 [==============================] - 21s 824us/step - loss: 0.1301 - acc: 0.9537\n",
      "Epoch 90/100\n",
      "25548/25548 [==============================] - 21s 830us/step - loss: 0.1276 - acc: 0.95583s - loss: 0 - E\n",
      "Epoch 91/100\n",
      "25548/25548 [==============================] - 21s 821us/step - loss: 0.1279 - acc: 0.9552\n",
      "Epoch 92/100\n",
      "25548/25548 [==============================] - 21s 808us/step - loss: 0.1229 - acc: 0.9571\n",
      "Epoch 93/100\n",
      "25548/25548 [==============================] - 21s 817us/step - loss: 0.1249 - acc: 0.9566\n",
      "Epoch 94/100\n",
      "25548/25548 [==============================] - 21s 814us/step - loss: 0.1226 - acc: 0.9596\n",
      "Epoch 95/100\n",
      "25548/25548 [==============================] - 21s 817us/step - loss: 0.1228 - acc: 0.9586\n",
      "Epoch 96/100\n",
      "25548/25548 [==============================] - 21s 819us/step - loss: 0.1220 - acc: 0.9590\n",
      "Epoch 97/100\n",
      "25548/25548 [==============================] - 21s 809us/step - loss: 0.1199 - acc: 0.9594\n",
      "Epoch 98/100\n",
      "25548/25548 [==============================] - 21s 816us/step - loss: 0.1172 - acc: 0.9603\n",
      "Epoch 99/100\n",
      "25548/25548 [==============================] - 21s 804us/step - loss: 0.1166 - acc: 0.9585\n",
      "Epoch 100/100\n",
      "25548/25548 [==============================] - 21s 806us/step - loss: 0.1115 - acc: 0.9609\n",
      "25548/25548 [==============================] - 6s 240us/step\n",
      "\n",
      "acc: 97.25%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(x_train,y_train,epochs=100);\n",
    "scores = model.evaluate(x_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 97.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "model.save('my.modelLSTM24hr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
